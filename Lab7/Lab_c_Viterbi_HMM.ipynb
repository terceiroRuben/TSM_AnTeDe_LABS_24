{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnTeDe Lab C: Viterbi Algorithm for HMM\n",
    "\n",
    "## Session goal\n",
    "\n",
    "The goal of this session is reproduce the example in Chapter 8 of **Speech and Language Processing** by Daniel Jurafsky & James H. Martin.\n",
    "\n",
    "We hardcode the same data used in the example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:59:51.831933500Z",
     "start_time": "2024-04-18T12:59:51.744101300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Probabilities:\n",
      "{'NNP': 0.2767, 'MD': 0.0006, 'VB': 0.0031, 'JJ': 0.0453, 'NN': 0.0449, 'RB': 0.051, 'DT': 0.2026}\n",
      "Transition Probabilities:\n",
      "{'NNP': {'NNP': 0.3777, 'MD': 0.011, 'VB': 0.0009, 'JJ': 0.0084, 'NN': 0.0584, 'RB': 0.009, 'DT': 0.0025}, 'MD': {'NNP': 0.0008, 'MD': 0.0002, 'VB': 0.7968, 'JJ': 0.0005, 'NN': 0.0008, 'RB': 0.1698, 'DT': 0.0041}, 'VB': {'NNP': 0.0322, 'MD': 0.0005, 'VB': 0.005, 'JJ': 0.0837, 'NN': 0.0615, 'RB': 0.0514, 'DT': 0.2231}, 'JJ': {'NNP': 0.0366, 'MD': 0.0004, 'VB': 0.0001, 'JJ': 0.0733, 'NN': 0.4509, 'RB': 0.0036, 'DT': 0.0036}, 'NN': {'NNP': 0.0096, 'MD': 0.0176, 'VB': 0.0014, 'JJ': 0.0086, 'NN': 0.1216, 'RB': 0.0177, 'DT': 0.0068}, 'RB': {'NNP': 0.0068, 'MD': 0.0102, 'VB': 0.1011, 'JJ': 0.1012, 'NN': 0.012, 'RB': 0.0728, 'DT': 0.0479}, 'DT': {'NNP': 0.1147, 'MD': 0.0021, 'VB': 0.0002, 'JJ': 0.2157, 'NN': 0.4744, 'RB': 0.0102, 'DT': 0.0017}}\n",
      "Emmission Probabilities:\n",
      "{'NNP': {'Janet': 3.2e-05, 'will': 0, 'back': 0, 'the': 4.8e-05, 'bill': 0}, 'MD': {'Janet': 0, 'will': 0.308431, 'back': 0, 'the': 0, 'bill': 0}, 'VB': {'Janet': 0, 'will': 2.8e-05, 'back': 0.000672, 'the': 0, 'bill': 2.8e-05}, 'JJ': {'Janet': 0, 'will': 0, 'back': 0.00034, 'the': 0, 'bill': 0}, 'NN': {'Janet': 0, 'will': 0.0002, 'back': 0.000223, 'the': 0, 'bill': 0.002337}, 'RB': {'Janet': 0, 'will': 0, 'back': 0.010446, 'the': 0, 'bill': 0}, 'DT': {'Janet': 0, 'will': 0, 'back': 0, 'the': 0.506099, 'bill': 0}}\n"
     ]
    }
   ],
   "source": [
    "import nltk.tokenize as tokenize\n",
    "\n",
    "sentence = \"Janet will back the bill\"\n",
    "\n",
    "observations = (\"Janet\", \"will\", \"back\", \"the\", \"bill\")\n",
    "observations = tokenize.word_tokenize(sentence)\n",
    "\n",
    "states = (\"NNP\", \"MD\", \"VB\", \"JJ\", \"NN\", \"RB\", \"DT\")\n",
    "starting_p_values = [0.2767, 0.0006, 0.0031, 0.0453, 0.0449, 0.0510, 0.2026]\n",
    "\n",
    "starting_p = {}\n",
    "\n",
    "for i, key in enumerate(states):\n",
    "    starting_p[key] = starting_p_values[i]\n",
    "\n",
    "print(\"Starting Probabilities:\")\n",
    "print(starting_p)\n",
    "\n",
    "valid_transitions = {}\n",
    "\n",
    "valid_transitions[\"NNP\"] = [0.3777, 0.0110, 0.0009, 0.0084, 0.0584, 0.0090, 0.0025]\n",
    "valid_transitions[\"MD\"] = [0.0008, 0.0002, 0.7968, 0.0005, 0.0008, 0.1698, 0.0041]\n",
    "valid_transitions[\"VB\"] = [0.0322, 0.0005, 0.0050, 0.0837, 0.0615, 0.0514, 0.2231]\n",
    "valid_transitions[\"JJ\"] = [0.0366, 0.0004, 0.0001, 0.0733, 0.4509, 0.0036, 0.0036]\n",
    "valid_transitions[\"NN\"] = [0.0096, 0.0176, 0.0014, 0.0086, 0.1216, 0.0177, 0.0068]\n",
    "valid_transitions[\"RB\"] = [0.0068, 0.0102, 0.1011, 0.1012, 0.0120, 0.0728, 0.0479]\n",
    "valid_transitions[\"DT\"] = [0.1147, 0.0021, 0.0002, 0.2157, 0.4744, 0.0102, 0.0017]\n",
    "\n",
    "transition_p = {}\n",
    "\n",
    "for key in valid_transitions:\n",
    "    transition_p[key] = {}\n",
    "    for i, state in enumerate(states):\n",
    "        transition_p[key][state] = valid_transitions[key][i]\n",
    "\n",
    "print(\"Transition Probabilities:\")\n",
    "print(transition_p)\n",
    "\n",
    "valid_emissions = {}\n",
    "valid_emissions[\"NNP\"] = {\n",
    "    \"Janet\": 0.000032,\n",
    "    \"the\": 0.000048,\n",
    "}\n",
    "valid_emissions[\"MD\"] = {\n",
    "    \"will\": 0.308431,\n",
    "}\n",
    "valid_emissions[\"VB\"] = {\n",
    "    \"will\": 0.000028,\n",
    "    \"back\": 0.000672,\n",
    "    \"bill\": 0.000028,\n",
    "}\n",
    "valid_emissions[\"JJ\"] = {\n",
    "    \"back\": 0.000340,\n",
    "}\n",
    "valid_emissions[\"NN\"] = {\n",
    "    \"will\": 0.000200,\n",
    "    \"back\": 0.000223,\n",
    "    \"bill\": 0.002337,\n",
    "}\n",
    "valid_emissions[\"RB\"] = {\n",
    "    \"back\": 0.010446,\n",
    "}\n",
    "valid_emissions[\"DT\"] = {\n",
    "    \"the\": 0.506099,\n",
    "}\n",
    "emission_p = {}\n",
    "\n",
    "for key in valid_emissions:\n",
    "    emission_p[key] = {}\n",
    "    for word in observations:\n",
    "        try:\n",
    "            emission_p[key][word] = valid_emissions[key][word]\n",
    "        except:\n",
    "            emission_p[key][word] = 0\n",
    "\n",
    "print(\"Emmission Probabilities:\")\n",
    "print(emission_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains an implementation of a Viterbi decoder for an HMM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T12:57:38.038584100Z",
     "start_time": "2024-04-18T12:57:37.994443200Z"
    }
   },
   "outputs": [],
   "source": [
    "def viterbi(observations, states, starting_p, transition_p, emission_p):\n",
    "    # your trellis is a list of dictionaries\n",
    "    trellis = [{}]\n",
    "\n",
    "    # first column of the trellis:\n",
    "    # how likely you are to start in each state, multiplied by\n",
    "    # how likely you are to generate the initial observation\n",
    "    # from each state\n",
    "    for state in states:\n",
    "        trellis[0][state] = {\n",
    "            \"probability\": starting_p[state] * emission_p[state][observations[0]],\n",
    "            \"previous state\": None,\n",
    "        }\n",
    "\n",
    "    # for loop over the trellis columns, left to right\n",
    "    for k in range(1, len(observations)):\n",
    "        # add a column\n",
    "        new_column = {}\n",
    "\n",
    "        # for each row in the column\n",
    "        for state in states:\n",
    "            max_path_p = 0\n",
    "\n",
    "            for previous_state in states:\n",
    "                up_to_here_p = (\n",
    "                    trellis[k - 1][previous_state][\"probability\"]\n",
    "                    * transition_p[previous_state][state]\n",
    "                )\n",
    "\n",
    "                if up_to_here_p > max_path_p:\n",
    "                    max_path_p = up_to_here_p\n",
    "\n",
    "                    prev_st_selected = previous_state\n",
    "\n",
    "            max_p = max_path_p * emission_p[state][observations[k]]\n",
    "\n",
    "            new_column[state] = {\"probability\": max_p, \"previous\": prev_st_selected}\n",
    "\n",
    "        trellis.append(new_column)\n",
    "\n",
    "    return trellis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn: run **viterbi** and obtain the trellis for our HMM.\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janet\n",
      "{'NNP': {'probability': 8.8544e-06, 'previous state': None}, 'MD': {'probability': 0.0, 'previous state': None}, 'VB': {'probability': 0.0, 'previous state': None}, 'JJ': {'probability': 0.0, 'previous state': None}, 'NN': {'probability': 0.0, 'previous state': None}, 'RB': {'probability': 0.0, 'previous state': None}, 'DT': {'probability': 0.0, 'previous state': None}}\n",
      "will\n",
      "{'NNP': {'probability': 0.0, 'previous': 'NNP'}, 'MD': {'probability': 3.00406859104e-08, 'previous': 'NNP'}, 'VB': {'probability': 2.2313087999999997e-13, 'previous': 'NNP'}, 'JJ': {'probability': 0.0, 'previous': 'NNP'}, 'NN': {'probability': 1.03419392e-10, 'previous': 'NNP'}, 'RB': {'probability': 0.0, 'previous': 'NNP'}, 'DT': {'probability': 0.0, 'previous': 'NNP'}}\n",
      "back\n",
      "{'NNP': {'probability': 0.0, 'previous': 'MD'}, 'MD': {'probability': 0.0, 'previous': 'MD'}, 'VB': {'probability': 1.6085273254449314e-11, 'previous': 'MD'}, 'JJ': {'probability': 5.106916604768e-15, 'previous': 'MD'}, 'NN': {'probability': 5.35925836641536e-15, 'previous': 'MD'}, 'RB': {'probability': 5.3284089852402517e-11, 'previous': 'MD'}, 'DT': {'probability': 0.0, 'previous': 'MD'}}\n",
      "the\n",
      "{'NNP': {'probability': 2.486139834207686e-17, 'previous': 'VB'}, 'MD': {'probability': 0.0, 'previous': 'RB'}, 'VB': {'probability': 0.0, 'previous': 'RB'}, 'JJ': {'probability': 0.0, 'previous': 'RB'}, 'NN': {'probability': 0.0, 'previous': 'VB'}, 'RB': {'probability': 0.0, 'previous': 'RB'}, 'DT': {'probability': 1.8161992521340703e-12, 'previous': 'VB'}}\n",
      "bill\n",
      "{'NNP': {'probability': 0.0, 'previous': 'DT'}, 'MD': {'probability': 0.0, 'previous': 'DT'}, 'VB': {'probability': 1.0170715811950793e-20, 'previous': 'DT'}, 'JJ': {'probability': 0.0, 'previous': 'DT'}, 'NN': {'probability': 2.013570710221386e-15, 'previous': 'DT'}, 'RB': {'probability': 0.0, 'previous': 'DT'}, 'DT': {'probability': 0.0, 'previous': 'DT'}}\n"
     ]
    }
   ],
   "source": [
    "# BEGIN_YOUR_CODE\n",
    "my_trellis = viterbi(observations, states, starting_p, transition_p, emission_p) \n",
    "\n",
    "# END_YOUR_CODE\n",
    "for i, column in enumerate(my_trellis):\n",
    "    print(observations[i])\n",
    "    print(column)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:59:43.393210700Z",
     "start_time": "2024-04-18T13:59:43.388137500Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn: write a function **get_pos_tag_sequence** that accepts the Viterbi-decoded trellis as input and prints out the tag for each word in the test sentence. Write a function that backtracks from the last column of the trellis to the first one to follow the most likely path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:05:41.621034800Z",
     "start_time": "2024-04-18T14:05:41.613517200Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pos_tag_sequence(trellis):\n",
    "    # BEGIN_YOUR_CODE\n",
    "    \n",
    "    global observations\n",
    "    num_words = len(trellis)\n",
    "\n",
    "    # Start by finding the state with the highest probability in the last column\n",
    "    last_column = trellis[-1]\n",
    "    max_prob = -1\n",
    "    best_state = None\n",
    "    for state, data in last_column.items():\n",
    "        if data['probability'] > max_prob:\n",
    "            max_prob = data['probability']\n",
    "            best_state = state\n",
    "\n",
    "    # Now backtrack from the last word to the first word using the 'previous' pointers\n",
    "    tags = [best_state]  # start with the best tag from the last column\n",
    "    current_state = best_state\n",
    "\n",
    "    # We iterate in reverse order\n",
    "    for i in range(num_words - 1, 0, -1):\n",
    "        current_state = trellis[i][current_state]['previous']\n",
    "        tags.insert(0, current_state)\n",
    "\n",
    "    # Combine the observations with their respective tags\n",
    "    observation_tag_pairs = [(observations[i], tags[i]) for i in range(num_words)]\n",
    "\n",
    "    # Print the sequence of tags with their corresponding observations\n",
    "    for word, tag in observation_tag_pairs:\n",
    "        print(f\"{word}\\t{tag}\")\n",
    "        \n",
    "    # END_YOUR_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janet\tNNP\n",
      "will\tMD\n",
      "back\tVB\n",
      "the\tDT\n",
      "bill\tNN\n"
     ]
    }
   ],
   "source": [
    "get_pos_tag_sequence(my_trellis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
